# Weather & Climate Analytics Pipeline ğŸŒ¦ï¸

## Project Overview
An end-to-end data pipeline that ingests, processes, and analyzes weather and climate data from multiple APIs. Built with Apache Airflow for orchestration, DuckDB for analytics, and Streamlit for visualization.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Weather APIs   â”‚â”€â”€â”€â”€â–¶â”‚   Airflow    â”‚â”€â”€â”€â”€â–¶â”‚   DuckDB    â”‚
â”‚  (OpenWeather,  â”‚     â”‚   Pipeline   â”‚     â”‚  Analytics  â”‚
â”‚   NOAA, etc)    â”‚     â”‚              â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                      â”‚
                              â–¼                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Great     â”‚     â”‚  Streamlit  â”‚
                        â”‚ Expectations â”‚     â”‚  Dashboard  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack
- **Orchestration**: Apache Airflow
- **Database**: DuckDB
- **Data Quality**: Great Expectations
- **Visualization**: Streamlit
- **Containerization**: Docker & Docker Compose
- **Language**: Python 3.11+

## Project Structure

```
/weather-climate-analytics-pipeline
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ weather_ingestion_dag.py
â”‚   â”‚   â”œâ”€â”€ climate_analysis_dag.py
â”‚   â”‚   â””â”€â”€ data_quality_dag.py
â”‚   â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Raw API responses
â”‚   â”œâ”€â”€ clean/            # Cleaned & validated data
â”‚   â””â”€â”€ analytics/        # Aggregated analytics tables
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploratory_analysis.ipynb
â”‚   â””â”€â”€ model_development.ipynb
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ components/
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ great_expectations/
â”‚   â”œâ”€â”€ expectations/
â”‚   â””â”€â”€ checkpoints/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api_clients/
â”‚   â”œâ”€â”€ transformations/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Data Sources

1. **OpenWeatherMap API**
   - Current weather data
   - 5-day forecast
   - Historical data

2. **NOAA Climate Data**
   - Historical climate records
   - Severe weather events
   - Climate normals

3. **Visual Crossing Weather API**
   - Historical weather data
   - Weather forecasts

## Features

### Data Pipeline
- âœ… Multi-source API integration with retry logic
- âœ… Incremental data loading
- âœ… Data quality validation with Great Expectations
- âœ… Error handling and alerting
- âœ… Geospatial data processing

### Analytics
- ğŸ“Š Time-series forecasting
- ğŸŒ¡ï¸ Temperature trend analysis
- ğŸŒ§ï¸ Precipitation patterns
- ğŸŒªï¸ Extreme weather event detection
- ğŸ“ Multi-city comparison

### Dashboard
- ğŸ“ˆ Real-time weather metrics
- ğŸ—ºï¸ Interactive maps
- ğŸ“‰ Historical trends
- ğŸ¯ Forecast accuracy tracking
- ğŸ“Š Climate change indicators

## Setup Instructions

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- API Keys (OpenWeatherMap, NOAA)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/ksarveshvenkatachalam-lang/weather-climate-analytics-pipeline.git
cd weather-climate-analytics-pipeline
```

2. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your API keys
```

3. **Start Airflow with Docker**
```bash
cd airflow
docker-compose up -d
```

4. **Access Airflow UI**
```
http://localhost:8080
Username: airflow
Password: airflow
```

5. **Run Streamlit Dashboard**
```bash
cd streamlit_app
streamlit run app.py
```

## Usage

### Running the Pipeline

1. **Enable DAGs** in Airflow UI
2. **Trigger manual run** or wait for scheduled execution
3. **Monitor progress** in Airflow task logs
4. **View results** in Streamlit dashboard

### Data Quality Checks

Great Expectations validates:
- API response completeness
- Temperature range validity
- Timestamp consistency
- Missing value thresholds
- Anomaly detection

## Business Value

### Skills Demonstrated
- **API Integration**: Multi-source data ingestion with authentication
- **Data Orchestration**: Complex DAG dependencies in Airflow
- **Data Quality**: Automated validation and monitoring
- **Analytics Engineering**: Time-series analysis and forecasting
- **Visualization**: Interactive dashboards with Streamlit
- **DevOps**: Dockerized deployment

### Use Cases
- **Agriculture**: Crop planning based on weather patterns
- **Energy**: Demand forecasting for heating/cooling
- **Insurance**: Risk assessment for weather-related claims
- **Logistics**: Route optimization based on weather
- **Retail**: Inventory planning for seasonal products

## Project Roadmap

- [x] Project setup and repository creation
- [ ] Airflow DAGs implementation
- [ ] API client development
- [ ] DuckDB schema design
- [ ] Great Expectations suite
- [ ] Streamlit dashboard
- [ ] Testing suite
- [ ] Documentation
- [ ] CI/CD pipeline

## Contributing
This is a portfolio project. Feel free to fork and adapt for your own use!

## License
MIT License

## Contact
Ksarvesh Venkatachalam - [GitHub](https://github.com/ksarveshvenkatachalam-lang)

---

**Note**: This project demonstrates production-grade data engineering practices suitable for enterprise environments across various industries.
